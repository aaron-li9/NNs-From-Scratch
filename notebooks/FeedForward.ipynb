{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/MNIST/train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu6(Z):\n",
    "    return np.clip(Z, 0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    e_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    probabilities = e_Z / np.sum(e_Z, axis=0, keepdims=True)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples, n_pixels = data.shape\n",
    "print(n_examples, n_pixels)\n",
    "validation_set_size = 2000\n",
    "data_validation = data[0:validation_set_size].T\n",
    "y_valid = data_validation[0]\n",
    "print(y_valid.shape)\n",
    "x_valid = data_validation[1:]\n",
    "print(x_valid.shape)\n",
    "data_train = data[validation_set_size:].T\n",
    "y_train = data_train[0]\n",
    "print(y_train.shape)\n",
    "x_train = data_train[1:]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = x_train.shape\n",
    "print(m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neurons = m\n",
    "hidden_1_neurons = 16\n",
    "hidden_2_neurons = 16\n",
    "output_neurons = 10\n",
    "def init_parameters():\n",
    "    \"\"\"\n",
    "    Randomly initializes weights based on He initialization and biases as a small number (0.01), as we are using Relu activations. \n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng()\n",
    "    r1 = np.sqrt(6/input_neurons)\n",
    "    r2 = np.sqrt(6/hidden_1_neurons)\n",
    "    r3 = np.sqrt(6/hidden_2_neurons)\n",
    "    w1 = rng.uniform(-r1, r1, size=(hidden_1_neurons, input_neurons))\n",
    "    w2 = rng.uniform(-r2, r2, size=(hidden_2_neurons, hidden_1_neurons))\n",
    "    w3 = rng.uniform(-r3, r3, size=(output_neurons, hidden_2_neurons))\n",
    "    b1 = np.full((hidden_1_neurons, 1), 0.01)\n",
    "    b2 = np.full((hidden_2_neurons, 1), 0.01)\n",
    "    b3 = np.full((output_neurons, 1), 0.01)\n",
    "    return w1, w2, w3, b1, b2, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2, w3, b1, b2, b3 = init_parameters()\n",
    "print(w1.shape)\n",
    "print(w2.shape)\n",
    "print(w3.shape)\n",
    "print(b1.shape)\n",
    "print(b2.shape)\n",
    "print(b3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, w1, w2, w3, b1, b2, b3):\n",
    "    \"\"\"\n",
    "    Forward propagation through the network, using a fully connected layer and non-linear activations at each step\n",
    "    Softmax for the output to represent each as a probability distribution  \n",
    "    \"\"\"\n",
    "    z_1 = w1 @ X + b1\n",
    "    A_1 = relu(z_1)\n",
    "    z_2 = w2 @ A_1 + b2\n",
    "    A_2 = relu(z_2)\n",
    "    z_3 = w3 @ A_2 + b3\n",
    "    A_3 = softmax(z_3)\n",
    "    return z_1, A_1, z_2, A_2, z_3, A_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1, A1, z2, A2, z3, A3 = forward_pass(x_train, w1, w2, w3, b1, b2, b3)\n",
    "\n",
    "#Testing for correct matrix dimensions and seeing some outputs\n",
    "print(z1.shape)\n",
    "print(z1[:,0])\n",
    "print(\"\")\n",
    "print(A1.shape)\n",
    "print(A1[:,0])\n",
    "print(\"\")\n",
    "print(z2.shape)\n",
    "print(z2[:,0])\n",
    "print(\"\")\n",
    "print(A2.shape)\n",
    "print(A2[:,0])\n",
    "print(\"\")\n",
    "print(z3.shape)\n",
    "print(z3[:,0])\n",
    "print(\"\")\n",
    "print(A3.shape)\n",
    "print(A3[:,0])\n",
    "\n",
    "print(sum(A3[:,0]))  #should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(Y):\n",
    "    \"\"\"\n",
    "    Converts Y (m by 1 vector with a label 0-9 for each training example) to a (10 by m) matrix.\n",
    "    10 represents the number of possible labels, and each column will have a single 1 representing the true correct label and the rest \n",
    "    0s. This establishes that the classes are not ordered in any way and allows loss function to be calculated easily by comparing the \n",
    "    predicted possibilities to the one-hot vector for each training example.\n",
    "    \"\"\"\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
